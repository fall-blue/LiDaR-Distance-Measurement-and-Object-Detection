# IRIS-Project
The project focuses on creating an indoor navigation device
for individuals with visual impairments. Combining YOLOv8
object detection, a TF-Luna LiDAR sensor, and a Raspberry
Pi 4, the system recognizes and measures the distance to
indoor objects within a 1.5 to 3-meter range. Utilizing Google
Text-to-Speech, the collected data is converted into spoken
messages for real-time auditory feedback through an
earpiece. The device emphasizes accessibility with voice
commands and tactile controls, offering an integrated
solution for safer and more independent navigation in indoor
environments.

Full Project Document: https://drive.google.com/file/d/1l9-GhlJRrnDzzOqASsGBT7DYZlVs8oO8/view?usp=drive_link
